{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNpAEucI1JGAxSjTEk0T9JQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","from diffusers import AutoPipelineForText2Image\n","from PIL import Image\n","\n","def run_image_gen(prompt, output_path=\"generated_image.png\"):\n","    # 1. Load the pre-trained SDXL model\n","    # We use float16 precision to save VRAM and speed up generation\n","    print(\"Loading model...\")\n","    pipe = AutoPipelineForText2Image.from_pretrained(\n","        \"stabilityai/stable-diffusion-xl-base-1.0\",\n","        torch_dtype=torch.float16,\n","        variant=\"fp16\",\n","        use_safetensors=True\n","    )\n","\n","    # 2. Move to GPU (Standard for 2026 workflows)\n","    pipe.to(\"cuda\")\n","\n","    # 3. Generate the image\n","    print(f\"Generating image for: '{prompt}'...\")\n","    image = pipe(\n","        prompt=prompt,\n","        num_inference_steps=30, # Quality vs Speed tradeoff\n","        guidance_scale=7.5      # How strictly to follow the prompt\n","    ).images[0]\n","\n","    # 4. Save and export\n","    image.save(output_path)\n","    print(f\"Success! Image saved to {output_path}\")\n","\n","if __name__ == \"__main__\":\n","    user_prompt = \"A futuristic cyberpunk city with neon lights and flying cars, digital art style\"\n","    run_image_gen(user_prompt)"],"metadata":{"id":"0jfU7XoTed8X"},"execution_count":null,"outputs":[]}]}